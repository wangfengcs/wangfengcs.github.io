<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[参数估计方法]]></title>
    <url>%2F2017%2F07%2F26%2F%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[几个参数估计的策略 期望损失(expected loss) 风险函数(risk function) 是模型$f(X)$关于联合分布$P(X,Y)$的期望 经验风险最小化 ERM(Empirical Risk Minimization) 是关于训练样本的平均损失 结构风险最小化 SRM(Structural Risk Minimization) 是加了正则项的经验风险最小化 P(x)与p(x)区别 大写$P(x)$表示概率质量函数 pmf (probability mass function) 小写$p(x)$表示概率密度函数 pdf (probability density function) 贝叶斯公式 $$P(\theta|X)=\frac{P(X|\theta) \cdot P(\theta)}{P(X)}$$ $$posterior=\frac{likelihood \cdot prior}{evidence}$$ 最大似然ML(Maximum likelihood)估计 $$P(\theta|X)=P(X|\theta)$$ $$posterior=likelihood$$ 在网上偶然找到一张图，可以看到在实际求解时，我们所求的往往是极大值而不是最大值。 { % asset_img 最大似然估计.png %} $$\begin{align} \hat \theta_{ML}&amp;=argmax_{\theta}logL \\ &amp;=argmax_{\theta}logP(X|\theta) \\ &amp;=argmax_{\theta}log\prod_xP(x|\theta) \\ &amp;=argmax_{\theta}\sum_xlogP(x|\theta) \\ \end{align}$$ 在实际应用中，模型分判别模型和生产模型，如果模型是判别模型，则似然估计为， $$\hat \theta_{ML}=argmax_{\theta}\sum_{i=1}^N logP(y_i|x_i,\theta)$$ 如果模型是生成模型，则似然估计为， $$\hat \theta_{ML}=argmax_{\theta}\sum_{i=1}^N logP(y_i,x_i|\theta)$$ 经验风险最小化 ERM(Empirical Risk Minimization) 当模型是条件概率分布，损失函数是对数损失时，判别模型的最大似然估计等同于经验风险最小化。 $\begin{align} \hat \theta_{ERM}&amp;=argmin_{f}\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i)) \\ &amp;=argmin_{\theta}\frac{1}{N}\sum_{i=1}^NL(y_i,P(y_i|x_i,\theta)) \\ &amp;=argmin_{\theta}\frac{1}{N}\sum_{i=1}^N{-logP(y_i|x_i,\theta)} \\ &amp;=argmax_{\theta}\frac{1}{N}\sum_{i=1}^NlogP(y_i|x_i,\theta) \\ &amp;=argmax_{\theta}\sum_{i=1}^NlogP(y_i|x_i,\theta) \end{align}$ 最大后验概率MAP(maximum a posteriori)估计 $$P(\theta|X)=P(X|\theta) \cdot P(\theta)$$ $$posterior=likelihood \cdot prior$$ 相比于最大似然估计，最大后验估计加入一个先验，根据贝叶斯公式计算出的整个后验概率最大。但因为只需要求使$P(\theta|X)$最大的$\theta$，这里$P(X)$与参数$\theta$无关，因此等价于使分子最大。 最大后验概率估计是不完整的后验概率估计；后面的贝叶斯估计是完整的后验概率估计 $\begin{align} \hat \theta_{MAP}&amp;=argmax_{\theta}logP(\theta|X) \\ &amp;=argmax_{\theta}log\frac{P(X|\theta)\cdot P(\theta)}{P(X)} \\ &amp;=argmax_{\theta}log(P(X|\theta)\cdot P(\theta)) \\ &amp;=argmax_{\theta}{logP(X|\theta)+logP(\theta)} \\ &amp;=argmax_{\theta}{log\prod_xP(x|\theta)+logP(\theta)} \\ &amp;=argmax_{\theta}{\sum_xlogP(x|\theta)+logP(\theta)} \end{align}$ 同样，在实际应用中，模型分判别模型和生产模型，如果模型是判别模型，则MAP估计为， $$\hat \theta_{MAP}=argmax_{\theta}\left\{\sum_{i=1}^NlogP(y_i|x_i,\theta)+logP(\theta)\right\}$$ 如果模型是生成模型，则MAP估计为， $$\hat \theta_{MAP}=argmax_{\theta}\left\{\sum_{i=1}^NlogP(y_i,x_i|\theta)+logP(\theta)\right\}$$ 结构风险最小化 SRM(Structural Risk Minimization) 当模型是条件概率分布，损失函数是对数损失，正则项为负log先验时，判别模型的MAP估计等同于结构风险最小化。 $\begin{align} \hat \theta_{SRM}&amp;=argmin_{f}{\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)} \\ &amp;=argmin_{\theta}{\frac{1}{N}\sum_{i=1}^NL(y_i,P(y_i|x_i,\theta))-\frac1NlogP(\theta)} \\ &amp;=argmin_{\theta}{\frac{1}{N}\sum_{i=1}^N{-logP(y_i|x_i,\theta)}-\frac1NlogP(\theta)} \\ &amp;=argmax_{\theta}{\frac{1}{N}\sum_{i=1}^NlogP(y_i|x_i,\theta)+\frac1NlogP(\theta)} \\ &amp;=argmax_{\theta}{\sum_{i=1}^NlogP(y_i|x_i,\theta)+logP(\theta)} \end{align}$ 贝叶斯估计(Bayesian estimator) $$P(\theta|X)= \frac{P(X|\theta) \cdot P(\theta)}{P(X)}$$ $$posterior= \frac{likelihood \cdot prior}{evidence}$$ Bayesian估计是后验的完整形式。 在MAP估计中，只取了后验P(θ|X)P(θ|X)的最大值作为θθ的估计，忽略了θθ的其他可能性，可能丢失信息。而Bayesian估计则把θθ的所有可能取值(分母部分)考虑进来，即， $$P(\theta|X)=\frac{P(X|\theta) \cdot P(\theta)}{P(X)}=\frac {P(X|\theta) \cdot P(\theta)}{\int_{\theta}P(X,\theta)d\theta}=\frac {P(X|\theta) \cdot P(\theta)}{\int_{\theta}P(X|\theta) \cdot P(\theta)d\theta}$$ 因此，Bayesian估计要比MAP估计更可靠些，但随着数据越多，Bayesian估计，MAP估计和ML估计越趋于一致。 优点 Bayesian估计不仅可以得到后验的期望，还可以得到后验的方差，表示对这个期望值的确信程度。常用共轭先验作先验，可以根据分布的参数直接得到方差。 Bayesian估计可以估计θθ后验分布上的某个具体的θθ值，而不是最大值，也就是Bayesian Inference。 缺点 Bayesian估计比较复杂，原因是分母$P(X)$不能在忽略，需要对$P(X|\theta)$在$P(\theta)$上求期望， $$P(\theta|X)=\frac{P(X|\theta) \cdot P(\theta)}{\int_{\theta}P(X|\theta) \cdot P(\theta)d\theta}$$ 总结 估计的复杂程度，ML&lt;MAP&lt;Bayesian ML估计最简单，posteriori=likelihoodposteriori=likelihood MAP估计，posteriori=likelihood⋅priorposteriori=likelihood⋅prior Bayesian估计，posteriori=likelihood⋅priorevidenceposteriori=likelihood⋅priorevidence ML估计和MAP估计都是点估计，返回的是参数变量θθ的特定值 MAP估计和Bayesian估计都需要先验。MAP估计只需要得到最大值，并不需要得到完整的后验，因此，可以不计算P(X)P(X)。而Bayesian估计是要得到完整的后验，所以需要计算P(X)P(X)。 MAP估计的后验是一个不完整的后验，因此，不能说得到的后验与先验共轭。而Bayesian估计是后验的完整形式，所以先验和后验关于似然共轭，这也是共轭先验的由来。 Bayesian估计可以求方差，表示确信度(confidence)，而且可以做推断(Inference)。 Reference https://zh.wikipedia.org/wiki/最大似然估计 https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation https://engineering.purdue.edu/kak/Trinity.pdf http://blog.csdn.net/yangliuy/article/details/829648]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朴素贝叶斯]]></title>
    <url>%2F2017%2F03%2F03%2F%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"><![CDATA[贝叶斯 朴素贝叶斯 朴素贝叶斯是基于贝叶斯定理和属性条件独立的分类器。其中，”朴素”指的是一个很naive的假设，即属性条件独立。 $$\begin{align} y&amp;=argmax_kP(c_k|x)\\ &amp;=argmax_k\frac{P(c_k)P(x|c_k)}{P(x)}\\ &amp;=argmax_kP(c_k)P(x|c_k)\\ &amp;=argmax_kP(c_k)\prod_{j=1}^DP(x^{(j)}|c_k)\\ &amp;=argmax_kP(c_k)\prod_{j=1}^D\frac{P(x^{(j)},c_k)}{P(c_k)}\\ &amp;=argmax_k \frac{\sum_{i=1}^NI(y_i=c_k)}N \prod_{j=1}^D\frac{\sum_{i=1}^NI(x_i^{(j)}=x^{(j)},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)}\\ &amp;=argmax_k\frac{N_k}{N}\prod_{j=1}^{D}\frac{N_k^{x^{(j)}}}{N_k} \end{align}$$ 上式第3步，因为分母于参数k无关，故舍去 上式第4步，因为naive，故属性条件独立 $x$表示需要预测的属性值向量，是values $y$表示预测的类别值，是values $D$表示属性个数 $D^{(j)}$表示第j个属性的取值数 $K$表示类别个数 $N$表示样本量 $N_k$表示属于k类的样本量 $N^{x^{(j)}}_k$表示属于k类，且第j个属性值为$x^{(j)}$的样本量 $x^{(j)}_i$表示第i个样例的第j个属性，是key $x^{(j)}$表示x的第j个属性值，是value 平滑 当数据量较小时，很容易出现$N^{x^{(j)}}_k$为0的情况，因此需要做平滑。 具体来说， $$\begin{align} y&amp;=argmax_k \frac{\sum_{i=1}^NI(y_i=c_k)}N \prod_{j=1}^D\frac{\sum_{i=1}^NI(x_i^{(j)}=x^{(j)},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)}\\ &amp;=argmax_k \frac{\sum_{i=1}^NI(y_i=c_k)+\lambda}{N+\lambda K} \prod_{j=1}^D\frac{\sum_{i=1}^NI(x_i^{(j)}=x^{(j)},y_i=c_k)+\lambda}{\sum_{i=1}^NI(y_i=c_k)+\lambda D^{(j)}}\\ &amp;=argmax_k\frac{N_k+\lambda}{N+\lambda K}\prod_{j=1}^{D}\frac{N_k^{x^{(j)}}+\lambda}{N_k+\lambda D^{(j)}} \end{align}$$ 预测时，最大后验概率的意义 再次强调，模型已经通过ML或者MAP估计好了，这里是预测时，朴素贝叶斯将实例分到后验概率最大的类中，等价于期望风险最小化。 $X$是输入随机向量，$Y$是输出随机变量 损失函数为0-1损失： $L(Y,f(X))= \begin{cases} 1, \ Y=f(X) \\ 0, \ Y\neq f(X) \end{cases} $ 则期望损失为： $R_{exp}(f)=E_{X\times Y}[L(Y,f(X))]$ 将期望损失分解成$P(Y|X)$条件期望的内部，和$P(X)$的外部形式: $\begin{align} R_{exp}(f) &amp;=E_{X\times Y}[L(Y,f(X))] \\ &amp;=\iint_{X\times Y}L(Y,f(X))P(Y,X)\\ &amp;=\iint_{X\times Y}L(Y,f(X))P(Y|X)P(X)\\ &amp;=\int_X\left\{\int_YL(Y,f(X))P(Y|X)\right\}P(X)\\ &amp;=\int_X\left\{\sum_{k=1}^KL(c_k,f(X))P(Y=c_k|X)\right\}P(X)\end{align}$ 当数据给定后，$P(X)$为定值，且不影响期望损失($f$的泛函)中对$f$的选择。 因此，为了使期望损失最小，只需要使得条件期望部分最小即可，具体来说，就是对$X=x$逐个极小化。 $$\begin{align} \hat f(x)&amp;=argmin_{f(x)}\sum_{k=1}^KL(c_k,f(x))P(Y=c_k|X=x) \\ &amp;=argmin_y\sum_{k=1}^KL(c_k,y)P(Y=c_k|X=x) \\ &amp;=argmin_y\sum_{k=1}^KL(c_k,y)P(c_k|X=x) \\ &amp;=argmin_y\sum_{k=1}^KP(y\neq c_k|X=x) \\ &amp;=argmin_y\left\{1-\sum_{k=1}^KP(y=c_k|X=x)\right\} \\ &amp;=argmin_y\left\{1-P(y=c_k|X=x)\right\} \\ &amp;=argmax_yP(y=c_k|X=x) \\ &amp;=argmax_{c_k}P(Y=c_k|X=x) \end{align}$$ 因此，期望风险最小等同于后验概率最大化。 Reference PRML]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经验贝叶斯]]></title>
    <url>%2F2017%2F03%2F01%2F%E7%BB%8F%E9%AA%8C%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"><![CDATA[贝叶斯 $\theta$ 是变量$x$的参数 $\eta$ 是变量$\theta$的参数 $\eta$ 是变量$x$的超参数 贝叶斯( Bayes or Standard Bayes or Fully Bayes ) 在给定数据之前，先验分布$p(\theta)$就已经确定下来了，即参数$\theta$的分布$p(\theta)$已知，$p(\theta)$表达式中的参数$\eta$已知。 $$p(\theta|x)=\frac{p(x|\theta)p(\theta)}{p(x)}$$ 经验贝叶斯(Empirical Bayes) 在给定数据之前，先验分布$p(\theta)$未知，即参数$\eta$未知。给定数据之后，先验分布是根据数据估计的，即确定使$p(x|\eta)$最大的超参数$\eta$的值。 $$\eta^*=argmax_{\eta}p(x|\eta)$$ $p(x|\eta)$ 表示关于$\eta$，而不是$\theta$的最大似然。将$p(x|\theta)$中的参数$\theta$替换成$p(\theta)$的表达式，表达式中，只包含超参数$\eta$，所以可以这么写。 然后根据$\eta^*$得到先验分布的估计，代入贝叶斯公式，其余的部分和贝叶斯都一样。 $$p(\theta|x) \approx \frac{p(x|\theta)p(\theta|\eta^*)}{p(x|\eta^*)}$$ 经验贝叶斯可以看成是贝叶斯的的近似，经验贝叶斯与贝叶斯也仅仅只有先验给定与估计的区别。 Others Empirical Bayes is only one of the possible approximations to a full Bayes treatment. There are many other approximation algorithms available, such as Variational Bayes and Expectation Propagation. Reference https://en.wikipedia.org/wiki/Empirical_Bayes_method http://stats.stackexchange.com/questions/115155/empirical-bayes-vs-non-informative-priors?rq=1]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于建模和模型评价的一些总结]]></title>
    <url>%2F2017%2F02%2F24%2F%E5%85%B3%E4%BA%8E%E5%BB%BA%E6%A8%A1%E5%92%8C%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[模型评估方法 网格搜索调参 在训练集上训练模型，根据验证集上的结果调参。调好参数后，在测试集上得到测试误差。 将数据集分为训练集，验证集，测试集 将参数网格化，每一个交叉点都是一组参数 遍历每个网格参数，在训练集上训练模型，在验证集上得到与网格参数对应的验证误差 挑选最小的验证误差所对应的那个网格参数，作为最优的参数 用最优参数设置模型，在训练集?验证集上训练，得到训练误差，在测试集上得到测试误差。 因为模型参数的选择是依赖于验证集，而模型对于测试集是没有依赖的，所以在测试上的准确率一般来说会比验证集低一些。 交叉验证 &amp; 估计期望泛化误差 用交叉验证的目的是为了得到可靠稳定的模型。如果已经调好参了，且得到的估计的期望泛化误差比较大，那么说明模型不太适用，就可以考虑做一些特征变化或换模型了。 在非测试集上交叉验证，用MSE估计期望泛化误差，在测试集上得到测试误差 将数据集分为非测试集和测试集 在将非测试集分为k份，其中k-1份作为训练集，另一份作为验证集 在训练集上训练模型，得到一个训练误差，在验证集上测试，得到一个验证误差。 共训练了k个模型，得到k个训练误差和k个验证误差。用k个验证误差的平均来估计期望泛化误差。 在非测试集上训练模型，得到训练误差，在测试集上测试模型，得到测试误差。 为了减小因样本划分不同而引起的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的平均。所以说，一共会训练pk个模型，并得到pk个验证误差。 如果只是为了估计模型的期望泛化误差，可以去掉验证集，并以测试集代替。 网格搜索 &amp; 交叉验证 比网格搜索更稳定些，因为评价的标准不再是单个的验证误差，而是k个验证误差的平均。 在非测试集上网格搜索并交叉验证，用MSE估计期望泛化误差，调参。调好参数后，在测试集上得到测试误差。 将数据集分为非测试集，测试集 将非测试集分为k份，其中k-1份作为训练集，另一份作为验证集 将参数网格化，每个交叉点都是一组参数 遍历每个网格参数，进行k交叉验证，共得到k个模型，k个训练误差，k个验证误差。用k个验证误差的平均来估计期望泛化误差，作为参数选择的评判标准。 选择估计期望泛化误差最小所对应的一个网格参数，作为最优参数 用最优参数设置模型，在非测试集上训练，得到训练误差，在测试集上得到测试误差 小结 对于给定的模型，确定了网络结构，确定了损失函数，确定了核的选择， 那么便确定了唯一的训练误差和测试误差，最优参数值的选择会根据网格搜索在验证集上确定。 如果模型的所有参数都确定了，那么就可以只用训练集和测试集了。 网格搜索是在验证集是调参用的。 交叉验证只是用于估计期望泛化误差。可以有验证集，也可以不用验证集。如果同时要得到训练的模型，训练误差，测试误差，那么就需要有验证集。 交叉验证可以使网格搜索的参数评判更准确。 如果不需要调参，那么就没必要有验证集了。 P-R曲线 &amp; ROC曲线 先列，后行 真实\预测 正例 反例 正例 TP(True Positive) FN(False Positive) 反例 FP(False Negative) TN(True Negative) TP：正确肯定的数目；FN：漏报，没有正确找到的匹配的数目； FP：误报，给出的匹配是不正确的；TN：正确拒绝的非匹配对数； P-R TPR 计算列1 显示列 FPR 计算行1 显示行 $TPR=\frac{TP}{TP+FN}$ $FPR=\frac {FP}{FP+TN}$ 准确率(Precision)，召回率(Recall)和F1-Score (1) 准确率(precision)：正确率 (2) 召回率(recall)：查全率 (3) F1-Score:准确率和召回率的综合指标 定义： $precision=\frac{true positive}{true positive+false negative}=\frac{true positive}{no.of predicted positive}$ $recall=\frac{true positive}{true positive+false negative}=\frac{true positive}{no.of actual positve}$ $F1-Score=2\times\frac{precision\times recall}{precision+recall}$ 正则 正则就是在训练数据的模型上加一个惩罚项，shrink模型的参数。 lasso的解是稀疏的，如sparse coding， compressed sensing 构造目标函数 用X来构造分布，用Y来确定分布的具体值。 构造概率函数。给定x，初始超参数，构造出一个概率函数。但此概率函数的变量是y，不是x。 构造似然函数。根据真实y，得到p(y|x)概率，连乘得到似然函数 优化的参数，其实是构造分布时的超参数。 不平衡类 对多的类进行欠采样 对少的类进行过采样 移动阈值$\frac{y}{1-y} \gt \frac{m^+}{m^-} $即为正类 少类的插值(kmeans聚类，然后在一个簇里面插值) 生成模型 &amp; 判别模型 生成模型 学习的是联合分布p(y,x) 可以由联合分布p(y,x)在y上积分得到p(x)，即类条件概率p(x|y)与p(y)在y上的积分，如果p(x)的概率比较小，说明可能是异常点(outlier)，该点的分类效果可能不好。对p(x,y)在y上的积分有时比较难求，需要用MCMC抽样方法得到p(x)或变分近似p(x)。 根据贝叶斯公式，p(y,x) / p(x)得到条件分布p(y|x)，即得到预测的条件分布。 当样本量较多时，生成模型能更快地收敛于真实模型。 可以解决存在隐变量的模型，比如GMM，HMM。 需要更大的样本，做判别的时候，有些信息用不到。 判别模型 学习的是条件分布p(y|x)，或判别函数f(x) 需要的样本量少于生成模型 寻找的是不同类别的最优分类面 准确率一般比生成模型高 可以对原数据X进行特征的变化，例如降维，特征选择 Reference http://blog.csdn.net/zouxy09/article/details/8195017 https://zhengyangcs.github.io/2016/08/19/模型综述/]]></content>
      <categories>
        <category>工具书，机器学习</category>
      </categories>
      <tags>
        <tag>工具书，机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关联规则]]></title>
    <url>%2F2017%2F02%2F10%2F%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[关联规则 关联规则就是有关联的规则，形式可以定义为：两个 不相交 的非空集合X、Y，如果有X-&gt;Y，就说X-&gt;Y是一条关联规则。关联规则的强度由支持度(support)和自信度(confidence)来描述。 支持度的定义：$$support(X–&gt;Y) = \frac{|X \cap Y|}{N}$$集合X与集合Y中的项在一条记录中同时出现的次数/数据记录的个数。 自信度的定义：$$confidence(X-&gt;Y)=\frac{|X \cap Y|}{|X|}$$表示集合X与集合Y中的项在一条记录中同时出现的次数/集合X出现的个数。 上述所讲的支持度和自信度都是相对的支持度和自信度，不是绝对支持度，绝对支持度为：$$abs_support=N*support, N为数据记录数$$ 支持度和自信度越高，说明规则越强，关联规则挖掘就是挖掘出满足一定强度的规则。 项集：属性名称集合。比如，{a,b},{c},{a,d} 如果一个项集同时满足最小支持度阈值和最小置信度阈值，则认为这个项集的关联规则是有趣的。 频繁项集：满足最小支持度的项集。 如果一个项集{a,b}是频繁的，那么它的所有子集{a}也是频繁的。 如果一个项集{a,b}是不频繁的，那么它的所有超集{a,b,c}也是不频繁的。 Apriori是找频繁项集的算法 Apriori算法：使用候选项集找频繁项集。Apriori算法是一种最有影响的挖掘布尔关联规则频繁项集的算法。其核心是基于两阶段频集思想的递推算法。该关联规则在分类上属于单维、单层、布尔关联规则。 统计一个元素项集出现的频数，找出不小于最小支持度的项集，得到 频繁1-项集。令k=2 根据第k-1步生成的 频繁(k-1)-项集 生成 侯选k-项集，然后对数据库进行搜索，得到 侯选k-项集 的支持度，与最小支持度进行比较，从而找到 频繁k-项集，删除 侯选k-项集 中 不频繁k-项集。 如果没有 频繁k-项集 生成，则停止，返回 频繁(k-1)-项集 作为 最大频繁项集； 否则，k = k+1，返回步骤2 优点： 简单，易理解，没有复杂的理论推导 缺点： 每一步产生侯选项集时循环产生的组合过多，没有排除不应该参与组合的元素 每次计算项集的支持度时，都会对数据库的全部记录进行扫描比较，I/O开销大 采用唯一支持度，算法的适应面窄]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mathjax语法总结]]></title>
    <url>%2F2017%2F02%2F04%2FMathjax%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[hexo写markdown中_与*一样，表示斜体或粗体，但mathjax中_表示下标，因此： mathjax中换行\，在markdown中写成\\ mathjax中下标_，在markdown改写成_ mathjax中下标{，在markdown改写成\{ mathjax中下标}，在markdown改写成\} 在markdown的表格中插入|，可以输入 &amp;#124; 代替 公式右键-Show Math As-Tex Commands可以查看编辑 1. 行中公式inline &amp; 独立公式displayed 行中公式 inline This is an example for $x_mu+ y_mu$. mathjax写法 This is an example for \$x_mu+ y_mu\$. 独立公式 displayed $$J\alpha(x) = \sum{m=0}^\infty \frac{(-1)^m}{m! \Gamma (m + \alpha + 1)} {\left({ \frac{x}{2} }\right)}^{2m + \alpha}$$ mathjax写法 $$J\alpha(x) = \sum{m=0}^\infty \frac{(-1)^m}{m! \Gamma (m + \alpha + 1)} {\left({ \frac{x}{2} }\right)}^{2m + \alpha}$$ 2. 表格 一种表格的生成方式： |col1 |col2 |col3 | |:-------|:--------|:--------| 内容行 col1 col2 col3 内容 内容 内容 3. 希腊字母 名称 大写 Tex 小写 Tex alpha $A$ A $\alpha$ \alpha beta $B$ B $\beta$ \beta gamma $\Gamma$ \Gamma $\gamma$ \gamma delta $\Delta$ \Delta $\delta$ \delta epsilon $E$ E $\epsilon$ \epsilon zeta $Z$ Z $\zeta$ \zeta eta $H$ H $\eta$ \eta theta $\Theta$ \Theta $\theta$ \theta iota $I$ I $\iota$ \iota kappa $K$ K $\kappa$ \kappa lambda $\Lambda$ \Lambda $\lambda$ \lambda mu $M$ M $\mu$ \mu nu $N$ N $\nu$ \nu xi $\Xi$ \Xi $\xi$ \xi omicron $O$ O $\omicron$ \omicron pi $\Pi$ \Pi $\pi$ \pi rho $P$ P $\rho$ \rho sigma $\Sigma$ \Sigma $\sigma$ \sigma tau $T$ T $\tau$ \tau upsilon $\Upsilon$ \Upsilon $\upsilon$ \upsilon phi $\Phi$ \Phi $\phi$ \phi chi $X$ X $\chi$ \chi psi $\Psi$ \Psi $\psi$ \psilon omega $\Omega$ \Omega $\omega$ \omega 运算符和数据符号 名称 显示 写法 加 $+$ + 减 $-$ - 乘 $\times \cdot \ast$ \times \cdot \ast 除 $\div$ \div 分数 $\frac{a}{b}$或${a}\over{b}$ \frac{a}{b}或{a}\over{b} 上标 $a^b$ a^b 下标 $x_y$ x_y 开二次方 $\sqrt x$ \sqrt x 开x次方 $\sqrt[x]{y}$ \sqrt[x] {y} 比较运算符 $\lt \gt \leq \geq \neq \approx \equiv$ \lt \gt \leq \geq \neq \approx \equiv 排列 $\binom{n+1}{2k}$ \binom{n+1}{2k} 小括号 $()$ () 中括号 $[]$ [] 大括号 ${}$ \{\} 上取整 $\lceil\rceil$ \lceil \rceil 下取整 $\lfloor \rfloor$ \lfloor \rfloor 逻辑运算符 $\land \lor \lnot \forall \exists$ \land \lor \lnot \forall \exists 偏导1 $\frac{\partial{f(x)}}{\partial{x}}$ \frac{\partial{f(x)}}{\partial{x}} 偏导2 $\nabla_xf(x)$ \nabla_xf(x) 集合1 $\cup \cap \in$ \cup \cap \in 集合2 $\bigcup \bigcap$ \bigcup \bigcap 估计 $\hat f(x)$ \hat f(x) 三角函数1 $sin(x)$ sin(x) 三角函数2 $arctan(x)arctan(x)$ arctan(x) 极限 $lim_{1\rightarrow+\infty}\frac{1}{n(n+1)}$ lim_{1\rightarrow+\infty}\frac{1}{n(n+1)} 未调整括号大小 $\{3+\frac{7x+5}{1+y^2}\}$ \{3+\frac{7x+5}{1+y^2}\} 调整括号大小 $\left\{3+\frac{7x+5}{1+y^2}\right\}$ \left\{3+\frac{7x+5}{1+y^2}\right} 求和 $\sum_1^n$ \sum_1^n 积分1 $\int_1^\infty$ \int_1^\infty 积分2 $\int_0^{+\infty}x^ne^{-x}dx$ \int_0^{+\infty}x^ne^{-x}dx 共轭转置 $U^{\dagger}U=UU^{\dagger}=I$ U^{\dagger}U=UU^{\dagger}=I 连乘 $\prod$ \prod 双积分 $\iint$ \iint 装饰符1 $\overline A \underline B$ \overline A \underline B 装饰符2 $\widetilde C \widehat D$ \widetilde C \widehat D 装饰符3 $\fbox E$ \fbox E 装饰符4 $\overleftarrow F \underrightarrow G$ \overleftarrow F \underrightarrow G 装饰符5 $\overleftrightarrow H \underleftrightarrow I$ \overleftrightarrow H \underleftrightarrow I 装饰符6 $\overbrace{(n-2)+\underbrace{(n-1)+n}}$ \overbrace{(n-2)+\underbrace{(n-1)+n}} 装饰符7 $\underbrace{a\cdot a\cdots a}_{b\text{times}}$ \underbrace{a\cdot a\cdots a}_{b\text{times}} 装饰符8 $\acute{I} \check{J} \grave{K}$ \acute{I} \check{J} \grave{K} 字体 名称 显示 写法 注意 黑板粗体1 $\mathbb{AaBb12} AaBb12 $ \mathbb{AaBb12} AaBb12 黑板粗体2 $\Bbb{AaBb12} AaBb12$ \Bbb{AaBb12} AaBb12 好像只有大写字母有变化 黑体 $\mathbf{AaBb12}$ \mathbf{AaBb12} 希腊字母黑体 $\boldsymbol{\mu sigma} $ \boldsymbol{\mu sigma} 罗马字体 $\mathrm{AaBb12} $ \mathrm{AaBb12} 手写体 $\mathscr{AaBb12}$ \mathscr{AaBb12} Fraktur字体 $\mathfrak{AaBb12}$ \mathfrak{AaBb12} 分类表达式 $$f(x)= \begin{cases} n=1, if\ x\ is\ even\\ n=2, if\ x\ is\ odd\\ n=3, if\ x\ is\ 0 \end{cases}$$ 表格 $$\begin{array}{c|cccc} n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} &amp; \text{last}\\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 &amp; 235 \\ 2 &amp; 0.24 &amp; 1 &amp; 125 &amp; 235 \\ 3 &amp; 0.24 &amp; 1 &amp; 125 &amp; 235 \\ \end{array}$$ 矩阵 $$\begin{pmatrix} 1 &amp; a_1 &amp; a_1^2 &amp; \cdots &amp; a_1^n \\ 1 &amp; a_2 &amp; a_2^2 &amp; \cdots &amp; a_2^n \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; a_n &amp; a_n^2 &amp; \cdots &amp; a_n^n \end{pmatrix}$$ 推导1 $\begin{align} E&amp;=\sum_{n=1}^{N}exp{-t_nf_{m-1}(\mathbf{x_n})-\frac12t_n\alpha_my_m(\mathbf{x_n})}\\ &amp; =\sum_{n=1}^{N}w_n^{(m)}exp\left\{-\frac12t_n\alpha_my_m(\mathbf{x_n})\right\} \end{align}$ 推导2 $\begin{align} \sqrt{37} &amp; = \sqrt{\frac{73^2-1}{12^2}} \\ &amp; = \sqrt{\frac{73^2}{12^2}\cdot\frac{73^2-1}{73^2}} \\ &amp; = \sqrt{\frac{73^2}{12^2}}\sqrt{\frac{73^2-1}{73^2}} \\ &amp; = \frac{73}{12}\sqrt{1 - \frac{1}{73^2}} \\ &amp; \approx \frac{73}{12}\left(1 - \frac{1}{2\cdot73^2}\right) \end{align}$ Reference http://blog.leanote.com/post/freewalk/Markdown-语法手册 https://zhengyangcs.github.io/2016/08/17/mathjax/ http://blog.csdn.net/wx11055/article/details/52694682]]></content>
      <categories>
        <category>工具书</category>
      </categories>
      <tags>
        <tag>工具书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[U盘快捷方式病毒处理方法]]></title>
    <url>%2F2017%2F01%2F16%2FU%E7%9B%98%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F%E7%97%85%E6%AF%92%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[当U盘文件变成快捷方式时，使用下面的代码解决: @echo off echo============================================ echo. echo U盘隐藏文件夹恢复 echo. echo============================================ pause rem echo 列出目录 dir /a:d /b &gt;yxkmp4dir.txt rem echo 列出目录外的所有文件 rem dir /a:s /a:-d /b for /f &quot;tokens=* delims= &quot; %%i in (yxkmp4dir.txt) do call :ss &quot;%%i&quot; del yxkmp4dir.txt echo. echo 全部修复完成,谢谢你的使用! echo. pause goto :eof :ss set var=%1 echo 正在修复文件夹 %var% ... attrib -s -h -r %var% goto :eof 将文件后缀改为bat,双击运行 除此之外，可以通过在文件夹选项中，选择显示全部隐藏文件，可以显示被隐藏的文件。]]></content>
      <categories>
        <category>工具书</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo简单指令]]></title>
    <url>%2F2017%2F01%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new "My New Post" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>工具书</category>
      </categories>
      <tags>
        <tag>工具书</tag>
      </tags>
  </entry>
</search>